{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52245f33",
   "metadata": {},
   "source": [
    "python prepare_datasets.py --train_source=data/example/raw/src-train.txt --train_target=data/example/raw/tgt-train.txt --val_source=data/example/raw/src-val.txt --val_target=data/example/raw/tgt-val.txt --save_data_dir=data/example/processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9a9bdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_path=r\"data/de-en/europarl-v7.de-en.de\"\n",
    "en_path=r\"data/de-en/europarl-v7.de-en.en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f59dde72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#需要把这里的数据划分为数据集和验证集。按1/10来吧\n",
    "import re\n",
    "\n",
    "def read_file(filepath):\n",
    "    with open(filepath, encoding='utf-8') as file:\n",
    "        lines = file.readlines() # 按行读取文件内容\n",
    "    data = []\n",
    "    for line in lines:\n",
    "        # 使用正则表达式把特殊字符加上空格\n",
    "        line = re.sub(r'([^\\w\\s])', r' \\1 ', line)\n",
    "        # 把多个空格合并成一个\n",
    "        line = re.sub(r'\\s+', ' ', line)\n",
    "        data.append(line.strip()) # 前后去掉空格并添加到列表中\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53c06972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920209 1920209\n"
     ]
    }
   ],
   "source": [
    "de_raw=read_file(de_path)\n",
    "en_raw=read_file(en_path)\n",
    "\n",
    "print(len(de_raw),len(en_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06e71196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_raw[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47c975aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'( The sitting was closed at 10 . 50 a . m . )'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_raw[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "124f8b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ich erkläre die am Freitag , dem 17 . Dezember unterbrochene Sitzungsperiode des Europäischen Parlaments für wiederaufgenommen , wünsche Ihnen nochmals alles Gute zum Jahreswechsel und hoffe , daß Sie schöne Ferien hatten .'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_raw[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2347f8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def train_val_split(data,val_rate=0.1):\n",
    "    n=int(len(data) * val_rate)\n",
    "    val_data = data[:n]\n",
    "    tra_data = data[n:]\n",
    "    return tra_data,val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8805824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728189 192020\n",
      "1728189 192020\n",
      "1717885 191035\n",
      "1717885 191035\n"
     ]
    }
   ],
   "source": [
    "en_tra,en_val=train_val_split(en_raw,val_rate=0.1)\n",
    "de_tra,de_val=train_val_split(de_raw,val_rate=0.1)\n",
    "\n",
    "print(len(en_tra),len(en_val))\n",
    "print(len(de_tra),len(de_val))\n",
    "\n",
    "de_tra, en_tra = zip(*[(de, en) for de, en in zip(de_tra, en_tra) if de and en])#清掉任意项为空的项\n",
    "de_val, en_val = zip(*[(de, en) for de, en in zip(de_val, en_val) if de and en])\n",
    "\n",
    "print(len(en_tra),len(en_val))\n",
    "print(len(de_tra),len(de_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1689bf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def write_to_txt_file(file_path, file_name, str_list):\n",
    "    \"\"\"将字符串列表输出到指定的txt文件中\"\"\"\n",
    "\n",
    "    # 如果指定的目录不存在，则创建目录\n",
    "    if not os.path.exists(file_path):\n",
    "        os.makedirs(file_path)\n",
    "\n",
    "    # 构造完整的文件路径\n",
    "    full_path = os.path.join(file_path, file_name)\n",
    "\n",
    "    # 使用with语句自动关闭文件流\n",
    "    with open(full_path, mode='w', encoding='utf-8') as f:\n",
    "        # 把字符串列表中的每个元素写入文件中\n",
    "        for s in str_list:\n",
    "            f.write(s + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7f15131",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder=\"data/de-en/raw\"\n",
    "write_to_txt_file(folder,\"tra_en.txt\",en_tra)\n",
    "write_to_txt_file(folder,\"val_en.txt\",en_val)\n",
    "\n",
    "write_to_txt_file(folder,\"tra_de.txt\",de_tra)\n",
    "write_to_txt_file(folder,\"val_de.txt\",de_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a16503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc223134",
   "metadata": {},
   "source": [
    "# 开始搭建语料库，做字典咯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33126e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_TOKEN = '<PAD>'#变成编码后，应该填充是0\n",
    "UNK_TOKEN = '<UNK>'#未知是1\n",
    "START_TOKEN = '<StartSent>'#开始是2\n",
    "END_TOKEN = '<EndSent>'#结束是3\n",
    "\n",
    "from os.path import dirname, abspath, join, exists\n",
    "import os\n",
    "BASE_DIR = os.getcwd() # 等价于这个，那种表示适用于脚本中获取当前的路径的\n",
    "\n",
    "train_source=\"data/de-en/raw/tra_en.txt\"\n",
    "train_target=\"data/de-en/raw/tra_de.txt\"\n",
    "val_source=\"data/de-en/raw/val_en.txt\"\n",
    "val_target=\"data/de-en/raw/val_de.txt\"\n",
    "save_data_dir=\"data/de-en/processed\"\n",
    "\n",
    "from datasets import TranslationDataset,TokenizedTranslationDataset,IndexedInputTargetTranslationDataset\n",
    "\n",
    "TranslationDataset.prepare(train_source, train_target, val_source, val_target, save_data_dir)#处理生成目标文件\n",
    "translation_dataset = TranslationDataset(save_data_dir, 'train')#读取train的数据集\n",
    "# translation_dataset_on_the_fly = TranslationDatasetOnTheFly('train')#一样，读取train的数据集\n",
    "# share_dictionary=False\n",
    "\n",
    "\n",
    "from dictionaries import IndexDictionary\n",
    "from utils.pipe import source_tokens_generator,target_tokens_generator\n",
    "\n",
    "tokenized_dataset = TokenizedTranslationDataset(save_data_dir, 'train')#\n",
    "source_generator = source_tokens_generator(tokenized_dataset)\n",
    "source_dictionary = IndexDictionary(source_generator, mode='source')\n",
    "target_generator = target_tokens_generator(tokenized_dataset)\n",
    "target_dictionary = IndexDictionary(target_generator, mode='target')\n",
    "\n",
    "source_dictionary.save(save_data_dir)\n",
    "target_dictionary.save(save_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57a68749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92349, 326269)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_dictionary.vocabulary_size,target_dictionary.vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "515da12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取，其实只要这么读就可以了，处理完后只需要运行这一个就行了\n",
    "source_dictionary = IndexDictionary.load(save_data_dir, mode='source',vocabulary_size=38000)\n",
    "target_dictionary = IndexDictionary.load(save_data_dir, mode='target',vocabulary_size=38000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a8f7ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "IndexedInputTargetTranslationDataset.prepare(save_data_dir, source_dictionary, target_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c719493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a18496e3",
   "metadata": {},
   "source": [
    "# 但实际上这些都没啥用，乐，具体有效的应该是vocabulary- .txt的文件。有这个就行了\n",
    "## 顺着跑到这里就行了\n",
    "\n",
    "```\n",
    "python train.py --data_dir=data/de-en/processed --save_config=checkpoints/de-en_config.json --save_checkpoint=checkpoints/de-en_model.pth --save_log=logs/de-en.log --positional_encoding --layers_count=4 --heads_count=4 --epochs=300 --batch_size=32 --vocabulary_size=38000\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a790ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
